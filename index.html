
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<!---
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
--->
<script src="load-mathjax.js" async></script>
<!-- Bootstrap CSS -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet">

<!-- Bootstrap JS and its dependencies (jQuery & Popper.js) -->
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

<script>
    $(document).ready(function(){
      $('[data-toggle="tooltip"]').tooltip(); 
    });
    function updatesingletaskreal() {
      var task = document.getElementById("single-menu-tasks-single-task-real").value;
      var rand = document.getElementById("single-menu-robustness-single-task-real").value;

      console.log("gpt", task, rand)

      var video = document.getElementById("single-task-result-video-single-task-rialto");
      map_task = {
        "mug_on_shelf": "mugandshelf",
        "book_on_shelf": "booknshelf",
        "plate_on_rack": "dishinrack",
        "open_kitchen_toaster": "kitchentoaster",
        "cup_in_trash": "cupntrash",
        "open_drawer": "drawer",
        "open_cabinet": "cabinet",
        "plate_on_rack_wild": "dishsinklab",

      }
      map_rand = {
        "disturbances": "disturbances",
        "distractors": "distractors",
        "object_pose": "rand",

      }
    
      video.src = "materials/videos/" + map_task[task] +  map_rand[rand] + ".mp4";
      console.log(video.src)
      video.play();

      var video = document.getElementById("single-task-result-video-single-task-imitation-learning");

      video.src = "materials/videos/" + map_task[task] +  map_rand[rand] + "il" + ".mp4";
      console.log(video.src)
      video.play();
    }

  </script>
  

<link rel="stylesheet" href="bootstrap-grid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title> Scaling Robot-Learning by Crowdsourcing Simulation Environments</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="Scaling Robot-Learning by Crowdsourcing Simulation Environments"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:creator" content="@marceltornev">
        <meta name="twitter:title" content="Scaling Robot-Learning by Crowdsourcing Simulation Environments">
        <meta name="twitter:description" content="">
        <meta name="twitter:image" content="">

          <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
        <script>
            window.dataLayer = window.dataLayer || [];

            function gtag() {
            dataLayer.push(arguments);
            }

            gtag('js', new Date());

            gtag('config', 'G-PYVRSFMDRL');
        </script>

        <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
                rel="stylesheet">

        <link rel="stylesheet" href="./static/css/bulma.min.css">
        <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
        <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
        <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
        <link rel="stylesheet"
                href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="./static/css/index.css">
        <link rel="icon" href="./static/images/favicon.svg">
        <link rel="stylesheet" href="style.css">
    

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script defer src="./static/js/fontawesome.all.min.js"></script>
        <script src="./static/js/bulma-carousel.min.js"></script>
        <script src="./static/js/bulma-slider.min.js"></script>
        <script src="./static/js/index.js"></script>

    </head>

 <body>


<div class="container">
    <div class="paper-title">
        <br><br>
    <h1> 
        Scaling Robot-Learning by Crowdsourcing Simulation Environments
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="https://marceltorne.github.io/">Marcel Torne<sup>1</sup></a>,
                <a href="">Arhan Jain<sup>2</sup></a>,
                <a href="">Vidyaaranya Macha<sup>2</sup></a>,
                <a href="">Jiayi Yuan<sup>2</sup></a>,
                <a href="">Lars Lien Ankile<sup>1</sup></a>,
                <a href="">Anthony Simeonov<sup>1</sup></a>,
                <a href="https://people.eecs.berkeley.edu/~pulkitag/">Pulkit Agrawal<sup>1*</sup></a>,
                <a href="https://abhishekunique.github.io">Abhishek Gupta<sup>2*</sup></a>
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span><sup>1</sup> Massachusetts Institute of Technology </span>
            <span><sup>2</sup> University of Washington</span>
        </div>
        <div class="affiliations">
          <span><sup>*</sup> Equal advising </span>
      </div>
<!-- 
        <div class="affil-row">
            <div class="venue text-center"><b>RSS 2024 </b></div>
        </div> -->

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="https://arxiv.org/abs/2403.03949">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <a class="paper-btn" href="https://github.com/real-to-sim-to-real/RialToPolicyLearning">
                <span class="material-icons"> code </span>
                Code
            </a>
            <a class="paper-btn" href="https://github.com/real-to-sim-to-real/RialToGUI">
                <span class="material-icons"> link </span>
                GUI 
            </a>
            <a class="paper-btn" href="https://github.com/real-to-sim-to-real/RialToAssets">
              <span class="material-icons"> link </span>
              Assets 
          </a>
            <!-- <a class="paper-btn" href="https://recorder-v3.slideslive.com/?share=88820&s=2fddd0c8-e26a-41cc-8de9-9e8e2ef2001e"  data-toggle="tooltip" title="Use Chrome to watch the video">
                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-camera-reels" viewBox="0 0 16 16">
                    <path d="M6 3a3 3 0 1 1-6 0 3 3 0 0 1 6 0M1 3a2 2 0 1 0 4 0 2 2 0 0 0-4 0"/>
                    <path d="M9 6h.5a2 2 0 0 1 1.983 1.738l3.11-1.382A1 1 0 0 1 16 7.269v7.462a1 1 0 0 1-1.406.913l-3.111-1.382A2 2 0 0 1 9.5 16H2a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2zm6 8.73V7.27l-3.5 1.555v4.35l3.5 1.556zM1 8v6a1 1 0 0 0 1 1h7.5a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1H2a1 1 0 0 0-1 1"/>
                    <path d="M9 6a3 3 0 1 0 0-6 3 3 0 0 0 0 6M7 3a2 2 0 1 1 4 0 2 2 0 0 1-4 0"/>
                  </svg>
                Talk
                </a> -->

                  
            </div>
        </div>
    </div>
    <div class="columns is-centered">
      <div class="column">
          <video id="method-video"
          muted
          autoplay
          loop

          width="80%">
          <source src="materials/videos/teaser.m4v"
          type="video/mp4">
          </video>
      </div>
      </div>
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/H0TQCbTSGVY?rel=0&amp;showinfo=0"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
          <h2 class="subtitle has-text-centered">
            <b>SCAR</b> robustifies robot policies by scaling up data collection and learning generalist policies, where human effort scales sublinearly with the number of environments where data is collected.
          </h2>
        </div>
      </div>
      <!--/ Paper video. -->
    
      <div class="columns is-centered">
        <div class="column">
          <img src="materials/images/scar-pipeline.gif" />
        </div>
        </div>

    <hr>

    <div class="columns is-centered">
        <div class="column is-three-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div id="abstract" class="flex-row">
            <p>
              Scaling robot learning requires data collection pipelines that scale favorably with human effort to ensure a 
              sufficient diversity and quality of expert data. In this work, we propose Scaling, Crowdsourcing and Amortizing 
              Real-to-sim-to-real - <b>SCAR</b>, a pipeline for scaling up data collection and learning generalist policies where 
              human effort scales sublinearly with the number of environments where data is collected. The key idea is to 
              crowdsource digital twins of real-world scenes using 3D reconstruction techniques and collect large-scale data 
              in these simulation scenes, rather than in the real-world. Data collection in simulation is initially driven by 
              reinforcement learning bootstrapped with human demonstrations. However, as the training of a generalist policy 
              progresses across environments, the generalization capabilities of the learned generalist policy can be used to 
              replace human effort with model generated demonstrations. This results in a pipeline where environments are easily 
              sourced from non-experts through 3D capture, while behavioral data is collected with continually reducing amounts of 
              human effort. We analyze the zero-shot and few-shot scaling laws of <b>SCAR</b> on two real-world tasks: placing mugs/bowls/cups 
              into a sink and placing boxes on a shelf across a diverse range of environments. We also demonstrate the capabilities 
              of the <b>SCAR</b> pipeline to finetune trained policies in a target scenario using a novel unsupervised fine-tuning 
              technique that can improve behavior simply using 3D environments scans at test time, without requiring additional 
              human demonstrations.
            </p>
        </div>
        </div>
      </div>
      <hr>

    </div>
    <section id="overview-videos">
    </div>

    </div>
       
        
    </section>


      <hr>

    

    <div class="columns is-centered">
        <div class="column">
          <h2 class="title is-3">RialTo Overview</h2>
          <h2 class="title is-4">1. Scan your target environment</h2>
          <div class="columns is-centered">
                <div class="column">
                    <video id="method-video"
                    controls
                    muted
                    autoplay
                    loop

                    width="80%">
                    <source src="materials/videos/scanvideo.mp4"
                    type="video/mp4">
                    </video>
                </div>
            </div>
          <h2 class="title is-4">2. Use RialTo's GUI to construct your environment</h2>
          <div class="columns is-centered">
            <div class="column">
                <video id="method-video"
                controls
                muted
                autoplay
                loop

                width="80%">
                <source src="materials/videos/guivideo.mp4"
                type="video/mp4">
                </video>
            </div>
            </div>
          <h2 class="title is-4">3. Collect demonstrations in the real world and transfer them to the simulation</h2>

          <div class="columns is-centered">
            <div class="column">
                <video id="method-video"
                controls
                muted
                autoplay
                loop

                width="80%">
                <source src="materials/videos/inversedistillvideo.mp4"
                type="video/mp4">
                </video>
            </div>
            </div>
          <h2 class="title is-4">4. RL fine-tuning in simulation</h2>
          <div class="columns is-centered">
            <div class="column">
                <video id="method-video"
                controls
                muted
                autoplay
                loop

                width="80%">
                <source src="materials/videos/rlfinetuningvideo.mp4"
                type="video/mp4">
                </video>
            </div>
            </div>

          <h2 class="title is-4">5. Teacher-student distillation with real-world demos co-training</h2>
          <div class="columns is-centered">
            <div class="column">
                <video id="method-video"
                controls
                muted
                autoplay
                loop

                width="80%">
                <source src="materials/videos/teacherstudentdistillationvideo.mp4"
                type="video/mp4">
                </video>
            </div>
            </div>
        </div>
      </div>

    <hr>

    <div class="columns is-centered">
      <div class="column">
          <h2 class="title is-3">Robustness Results</h2>
          Task    
          <div class="select is-small">     
            <select id="single-menu-tasks-single-task-real" onchange="updatesingletaskreal()">
      <option value="plate_on_rack">plate_on_rack</option>
      <option value="mug_on_shelf" selected="selected">mug_on_shelf</option> 
      <option value="book_on_shelf">book_on_shelf</option>        
      <option value="open_kitchen_toaster">open_kitchen_toaster</option>
      <option value="cup_in_trash">cup_in_trash</option>
      <option value="open_drawer">open_drawer</option>
      <option value="plate_on_rack_wild">plate_on_rack_wild</option>
      
            </select>
          </div>
          robustness to
          <div class="select is-small">
            <select id="single-menu-robustness-single-task-real" onchange="updatesingletaskreal()">
            <option value="object_pose" >object_pose</option>
            <option value="distractors">distractors</option>
            <option value="disturbances" selected="selected">disturbances</option>
            </select>
          </div>
          <div class="container  ">
              <!-- Paper video. -->
              <div class="columns is-centered has-text-centered">
                <div class="column one-third"  width="30%">
                  <h3 class="title is-4">RialTo</h3>
          
                  <div class="columns">
                    <div class="column has-text-centered">			
                      <video id="single-task-result-video-single-task-rialto"
                             controls
                             muted
                             autoplay
                             loop
  
                             width="80%">
                        <source src="materials/videos/mugandshelfdisturbances.mp4"
                                type="video/mp4">
                      </video>
                    </div>
                  </div>
              </div>        
                <div class="column is-half">
                  <h3 class="title is-4">Imitation Learning</h3>
                  <div class="columns">
                    <div class="column has-text-centered">		
                      <video  border-radius="10px" poster="" autoplay controls muted loop playsinline id="single-task-result-video-single-task-imitation-learning"
                             controls
                             muted
                             autoplay
                             loop
                             width="80%">
                        <source src="materials/videos/mugandshelfdisturbancesil.mp4"
                                type="video/mp4">
                      </video>
                    </div>
                  </div>
              </div>
  
      </div>
      <hr>
       

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
          <h2 class="title">BibTeX</h2>
          <pre><code>@article{torne2024rialto,
        author    = {Torne, Marcel 
                    and Simeonov, Anthony 
                    and Li, Zechu 
                    and Chan, April 
                    and Chen, Tao 
                    and Gupta, Abhishek 
                    and Agrawal, Pulkit},
        title     = {Scaling Robot-Learning by Crowdsourcing Simulation Environments},
        journal   = {Arxiv},
        year      = {2024},
      }</code></pre>
        </div>
      </section>
      
      
      <footer class="footer">
          <div class="columns is-centered">
              <div class="content">
                <p>
                    This webpage template was inspired from <a href='https://nv-tlabs.github.io/LION/'>LION</a>, <a href='https://nerfies.github.io'>Nerfies</a>, <a href='https://liruiw.github.io/policycomp/'>PoCo</a> and <a href='https://human-guided-exploration.github.io/HuGE/'>HuGE</a>.
                </p>
            </div>
        </div>
      </footer>
      


</div>
</body>
</html>
